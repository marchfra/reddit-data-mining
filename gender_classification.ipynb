{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit user gender classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['grid', 'science', 'notebook', 'mylegend'])\n",
    "\n",
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(load_test: bool) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    train_data = pd.read_csv(f'{data_dir}/train_data.csv')\n",
    "    target = pd.read_csv(f'{data_dir}/train_target.csv')\n",
    "    if load_test:\n",
    "        test_data = pd.read_csv(f'{data_dir}/test_data.csv')\n",
    "    else:\n",
    "        test_data = pd.DataFrame()\n",
    "    return train_data, target, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors in training set: 5000\n"
     ]
    }
   ],
   "source": [
    "train_data, target, test_data = load_data(load_test=True)\n",
    "\n",
    "print(f\"Number of authors in training set: {train_data[\"author\"].unique().shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subreddit_idx(data: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Map every subreddit to a unique integer.\"\"\"\n",
    "    subreddits = data[\"subreddit\"].unique()\n",
    "    return pd.Series(index=subreddits, data=np.arange(len(subreddits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subreddits(\n",
    "    author_data: pd.DataFrame,\n",
    "    subreddit_idx: pd.Series,\n",
    ") -> sp.csr_array:\n",
    "    \"\"\"\n",
    "    This function converts all the subreddits the author has posted in into a sparse\n",
    "    array of length N (where N is the number of subreddits in the dataset) with 1s in\n",
    "    the indexes of the subreddits the author has posted in.\n",
    "    \"\"\"\n",
    "    user_subs = author_data[\"subreddit\"]\n",
    "    subs_in_idx = user_subs.isin(subreddit_idx.index)\n",
    "    user_subs = user_subs[subs_in_idx].to_numpy()\n",
    "\n",
    "    # idxs is an array with the indexes of the subreddits in subreddits_idx\n",
    "    idxs = subreddit_idx.loc[user_subs].to_numpy()\n",
    "\n",
    "    # create a sparse array indicating the subreddits the author has posted in\n",
    "    v = sp.dok_array((1, len(subreddit_idx)))  # dok = dictionary of keys\n",
    "    for idx in idxs:\n",
    "        v[0, idx] = 1\n",
    "    return v.tocsr()  # convert to compressed sparse row format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(author_data: pd.DataFrame) -> str:\n",
    "    \"\"\"Returns all the posts of an author as a single string.\"\"\"\n",
    "    group_text = author_data[\"body\"].astype(str).to_numpy()\n",
    "    return \" \".join(group_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(\n",
    "    vectorizer: TfidfVectorizer,\n",
    "    text: list[str],\n",
    "    data_is_test: bool,\n",
    ") -> sp.csr_array:\n",
    "    \"\"\"\n",
    "    This function vectorizes the text of an author using the provided vectorizer.\n",
    "    If the data is test data, the vectorizer is only transformed, otherwise it is fit\n",
    "    and transformed.\n",
    "    \"\"\"\n",
    "    if data_is_test:\n",
    "        return vectorizer.transform(text)\n",
    "    else:\n",
    "        return vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(\n",
    "    data: pd.DataFrame,\n",
    "    subreddit_idx: pd.Series,\n",
    "    vectorizer: TfidfVectorizer,\n",
    "    *,\n",
    "    target: pd.DataFrame | None = None,\n",
    ") -> tuple[sp.csr_matrix, pd.Series] | sp.csr_matrix:\n",
    "    \"\"\"Extract features from the data.\"\"\"\n",
    "\n",
    "    data_is_test = True if target is None else False\n",
    "\n",
    "    subs_dict: dict[str, sp.csr_array] = {}\n",
    "    for author, group in data.groupby(\"author\"):\n",
    "        subs_dict[author] = extract_subreddits(group, subreddit_idx)\n",
    "\n",
    "    if data_is_test:\n",
    "        authors = data[\"author\"].unique()\n",
    "    else:\n",
    "        authors = target[\"author\"]\n",
    "\n",
    "    # Generate a sparse matrix with the authors as rows\n",
    "    # and the subreddits they have posted in as columns\n",
    "    subs_matrix: sp.csr_matrix = sp.vstack([subs_dict[author] for author in authors])\n",
    "\n",
    "    text_dict: dict[str, str] = {}\n",
    "    for author, group in data.groupby(\"author\"):\n",
    "        text_dict[author] = extract_text(group)\n",
    "\n",
    "    author_text: list[str] = [text_dict[author] for author in authors]\n",
    "    text_features = vectorize_text(vectorizer, author_text, data_is_test)\n",
    "\n",
    "    # print(type(text_features))\n",
    "\n",
    "    X = sp.hstack([subs_matrix, text_features])\n",
    "\n",
    "    if data_is_test:\n",
    "        return X\n",
    "    else:\n",
    "        y: pd.Series = target[\"gender\"]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_idx = create_subreddit_idx(train_data)\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, stop_words=\"english\", max_features=10000)  #Â max_features needs to be tuned !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_features(train_data, subreddit_idx, vectorizer, target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a set of models to try on the dataset. Then, for each model, perform hyperparameters tuning using `GridSearchCV`. Finally, pick the best model overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "\n",
    "classifiers = {\"LogReg\": LogReg(n_jobs=-1),\n",
    "               \"SVM\": SVC(probability=True),\n",
    "               \"KNN\": KNN(n_jobs=-1),\n",
    "            #    \"Naive Bayes\": NB(),\n",
    "               \"Decision Tree\": DT(),\n",
    "               \"Gradient Boosting\": GBC(),\n",
    "               \"Random Forest\": RF(n_jobs=-1),\n",
    "               \"MultiLayer Perceptron\": MLP(),\n",
    "}\n",
    "\n",
    "# for name, clf in classifiers.items():\n",
    "#     print(f\"{name} -- parameters: {clf.get_params()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogReg                -- score = 0.901\n",
      "Training SVM                   -- score = 0.866\n",
      "Training KNN                   -- score = 0.700\n",
      "Training Decision Tree         -- score = 0.661\n",
      "Training Gradient Boosting     -- score = 0.850\n",
      "Training Random Forest         -- score = 0.834\n",
      "Training MultiLayer Perceptron -- score = 0.905\n"
     ]
    }
   ],
   "source": [
    "param_grids = [\n",
    "    {\"C\": np.logspace(0, 3)},\n",
    "    [\n",
    "        {\n",
    "            \"C\": np.logspace(0, 3),\n",
    "            \"kernel\": \"linear\",\n",
    "        },\n",
    "        {\n",
    "            \"C\": np.logspace(0, 3),\n",
    "            \"kernel\": \"rbf\",\n",
    "            \"gamma\": [\"scale\", \"auto\", 1.0e-3, 1.0e-4],\n",
    "        },\n",
    "        {\n",
    "            \"C\": np.logspace(0, 3),\n",
    "            \"kernel\": \"poly\",\n",
    "            \"degree\": np.arange(2, 5),\n",
    "            \"gamma\": [\"scale\", \"auto\", 1.0e-3, 1.0e-4],\n",
    "        },\n",
    "    ],\n",
    "    {\"n_neighbors\": np.arange(1, 10), \"weights\": [\"uniform\", \"distance\"]},\n",
    "    # {},\n",
    "    {\"max_depth\": np.arange(1, 10), \"min_samples_split\": np.arange(2, 5)},\n",
    "    {\n",
    "        \"n_estimators\": np.arange(1, 100, 10),\n",
    "        \"learning_rate\": np.logspace(-3, 0),\n",
    "        \"max_depth\": np.arange(1, 5),\n",
    "    },\n",
    "    {\"n_estimators\": np.arange(1, 100, 10)},\n",
    "    {\n",
    "        \"hidden_layer_sizes\": [(100,), (20, 5), (10, 10, 5)],\n",
    "        \"activation\": [\"logistic\", \"relu\"],\n",
    "        \"solver\": \"adam\",\n",
    "        \"alpha\": np.logspace(-3, 0),\n",
    "        \"learning_rate\": [\"constant\", \"adaptive\"],\n",
    "        \"learning_rate_init\": np.logspace(-3, 0),\n",
    "        \"early_stopping\": [True, False],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clfs = {}\n",
    "best_pars = {}\n",
    "for (name, clf), param_grid in zip(classifiers.items(), param_grids):\n",
    "    print(f\"Training {name:21} -- \", end=\"\")\n",
    "    search = GridSearchCV(clf, param_grid, cv=5, scoring='roc_auc')\n",
    "    t_start = time()\n",
    "    search.fit(X, y)\n",
    "    t_end = time()\n",
    "    best_clfs[name] = search.best_estimator_\n",
    "    best_pars[name] = search.best_params_\n",
    "    print(f\"score = {search.best_score_:.3f}, time = {t_end - t_start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring LogReg                time = 1.61s\n",
      "Scoring SVM                   time = 127.56s\n",
      "Scoring KNN                   time = 0.66s\n",
      "Scoring Decision Tree         time = 4.77s\n",
      "Scoring Gradient Boosting     time = 53.32s\n",
      "Scoring Random Forest         time = 1.82s\n",
      "Scoring MultiLayer Perceptron time = 50.77s\n"
     ]
    }
   ],
   "source": [
    "best_scores_cv = {}\n",
    "for name, clf in best_clfs.items():\n",
    "    print(f\"Scoring {name:21}\", end=\" \")\n",
    "    t_start = time()\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='roc_auc')\n",
    "    t_end = time()\n",
    "    best_scores_cv[name] = scores\n",
    "    print(f\"time = {t_end - t_start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier            Score\n",
      "LogReg                0.905 +/- 0.010\n",
      "SVM                   0.874 +/- 0.006\n",
      "KNN                   0.708 +/- 0.013\n",
      "Decision Tree         0.676 +/- 0.006\n",
      "Gradient Boosting     0.862 +/- 0.001\n",
      "Random Forest         0.834 +/- 0.004\n",
      "MultiLayer Perceptron 0.902 +/- 0.012\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier            Score\")\n",
    "for name, scores in best_scores_cv.items():\n",
    "    print(f\"{name:21} {scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = {name: (scores.mean(), scores.std()) for name, scores in best_scores_cv.items()}\n",
    "best_clf_name = max(best_scores, key=lambda k: best_scores[k][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = best_clfs[best_clf_name]\n",
    "joblib.dump(best_clf, f\"{data_dir}/best_clf.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = extract_features(test_data, subreddit_idx, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ejchristian86</td>\n",
       "      <td>0.999964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>0.003767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>savoytruffle</td>\n",
       "      <td>0.012911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hentercenter</td>\n",
       "      <td>0.067573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rick-o-suave</td>\n",
       "      <td>0.259905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author    gender\n",
       "0  ejchristian86  0.999964\n",
       "1      ZenDragon  0.003767\n",
       "2   savoytruffle  0.012911\n",
       "3   hentercenter  0.067573\n",
       "4   rick-o-suave  0.259905"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution = pd.DataFrame({\"author\": test_data.author.unique(), \"gender\": y_pred})\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit_data_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
