{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a8906df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:12.684122Z",
     "iopub.status.busy": "2024-04-04T23:24:12.683274Z",
     "iopub.status.idle": "2024-04-04T23:24:13.660730Z",
     "shell.execute_reply": "2024-04-04T23:24:13.658406Z"
    },
    "papermill": {
     "duration": 0.990345,
     "end_time": "2024-04-04T23:24:13.663526",
     "exception": false,
     "start_time": "2024-04-04T23:24:12.673181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19387aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbcbae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeadc76a",
   "metadata": {
    "_uuid": "7bb9aeff202a934258f69ac6ad278b9c5c4d739c",
    "papermill": {
     "duration": 0.006729,
     "end_time": "2024-04-04T23:24:13.677527",
     "exception": false,
     "start_time": "2024-04-04T23:24:13.670798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467a0f37",
   "metadata": {
    "_uuid": "03006e40a92e2e374a494f4abb15d2fefe56d3ff",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:13.695482Z",
     "iopub.status.busy": "2024-04-04T23:24:13.694462Z",
     "iopub.status.idle": "2024-04-04T23:24:15.711243Z",
     "shell.execute_reply": "2024-04-04T23:24:15.709818Z"
    },
    "papermill": {
     "duration": 2.029311,
     "end_time": "2024-04-04T23:24:15.714318",
     "exception": false,
     "start_time": "2024-04-04T23:24:13.685007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shamus_Aran</td>\n",
       "      <td>mylittlepony</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>I don't think we'd get nearly as much fanficti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Riddance</td>\n",
       "      <td>sex</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>Thanks. I made it up, that's how I got over my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Secret_Wizard</td>\n",
       "      <td>DragonsDogma</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>Are you sure you aren't confusing Cyclops (the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Penultimatum</td>\n",
       "      <td>malefashionadvice</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>dont do this to me bro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7-SE7EN-7</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>That's what we do when we can't find a mate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author          subreddit   created_utc  \\\n",
       "0    Shamus_Aran       mylittlepony  1.388534e+09   \n",
       "1       Riddance                sex  1.388534e+09   \n",
       "2  Secret_Wizard       DragonsDogma  1.388534e+09   \n",
       "3   Penultimatum  malefashionadvice  1.388534e+09   \n",
       "4      7-SE7EN-7      todayilearned  1.388534e+09   \n",
       "\n",
       "                                                body  \n",
       "0  I don't think we'd get nearly as much fanficti...  \n",
       "1  Thanks. I made it up, that's how I got over my...  \n",
       "2  Are you sure you aren't confusing Cyclops (the...  \n",
       "3                             dont do this to me bro  \n",
       "4        That's what we do when we can't find a mate  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(f\"{data_dir}/train_data.csv\", encoding=\"utf8\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e5c621",
   "metadata": {
    "_uuid": "cf29c3c9b927020503dfb6e41d92f9e380915834",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:15.770478Z",
     "iopub.status.busy": "2024-04-04T23:24:15.770056Z",
     "iopub.status.idle": "2024-04-04T23:24:15.806297Z",
     "shell.execute_reply": "2024-04-04T23:24:15.805197Z"
    },
    "papermill": {
     "duration": 0.047374,
     "end_time": "2024-04-04T23:24:15.809032",
     "exception": false,
     "start_time": "2024-04-04T23:24:15.761658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.author.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee12d5b",
   "metadata": {
    "_uuid": "a5bbaa115e83a571c86fcd07277118f0c729a514",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:15.825551Z",
     "iopub.status.busy": "2024-04-04T23:24:15.825126Z",
     "iopub.status.idle": "2024-04-04T23:24:15.838142Z",
     "shell.execute_reply": "2024-04-04T23:24:15.836905Z"
    },
    "papermill": {
     "duration": 0.024025,
     "end_time": "2024-04-04T23:24:15.840494",
     "exception": false,
     "start_time": "2024-04-04T23:24:15.816469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RedThunder90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lirkmor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In0chi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ProjectGrudge</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TehTurtleHermit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author  gender\n",
       "0     RedThunder90       0\n",
       "1          Lirkmor       1\n",
       "2           In0chi       0\n",
       "3    ProjectGrudge       0\n",
       "4  TehTurtleHermit       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv(f\"{data_dir}/train_target.csv\", encoding=\"utf8\")\n",
    "target.head()  # 1 - male; 0 - female"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b317f6d",
   "metadata": {
    "_uuid": "787021ec7da4ec1a1b2296c1bc67d8b64f278d43",
    "papermill": {
     "duration": 0.007136,
     "end_time": "2024-04-04T23:24:15.885635",
     "exception": false,
     "start_time": "2024-04-04T23:24:15.878499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee503d34",
   "metadata": {
    "_uuid": "4ae83bc0a51e4edcda8903dda7b1ea9971bd8dbc",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:15.902668Z",
     "iopub.status.busy": "2024-04-04T23:24:15.901881Z",
     "iopub.status.idle": "2024-04-04T23:24:15.930940Z",
     "shell.execute_reply": "2024-04-04T23:24:15.929711Z"
    },
    "papermill": {
     "duration": 0.040341,
     "end_time": "2024-04-04T23:24:15.933435",
     "exception": false,
     "start_time": "2024-04-04T23:24:15.893094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subreddits = train_data.subreddit.unique()\n",
    "# subreddits_map is a series that associates a subreddit with an index\n",
    "# why this is absolutely necessary is still unclear\n",
    "subreddits_map = pd.Series(index=subreddits, data=np.arange(subreddits.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afe5be2b",
   "metadata": {
    "_uuid": "fe7ee5926b14f2e1a338f9e7a8cd4d13d87b13b7",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:16.316521Z",
     "iopub.status.busy": "2024-04-04T23:24:16.315886Z",
     "iopub.status.idle": "2024-04-04T23:24:16.361265Z",
     "shell.execute_reply": "2024-04-04T23:24:16.360104Z"
    },
    "papermill": {
     "duration": 0.057004,
     "end_time": "2024-04-04T23:24:16.363468",
     "exception": false,
     "start_time": "2024-04-04T23:24:16.306464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 1 stored elements and shape (1, 3468)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_features(group: pd.DataFrame) -> sparse.csr_matrix:\n",
    "    \"\"\"\n",
    "    This function converts all the subreddits the author has posted in into a 1xN sparse\n",
    "    matrix (where N is the number of subreddits in the dataset) with 1s in the indexes\n",
    "    of the subreddits the author has posted in.\n",
    "    \"\"\"\n",
    "    # this basically converts group['subreddit'] to an array of subreddits\n",
    "    # why on earth it is done like this is beyond me\n",
    "    group_subreddits = group['subreddit']\n",
    "    group_subreddits = group_subreddits[group_subreddits.isin(subreddits_map.index)].values\n",
    "\n",
    "    # idxs is an array with the indexes of the subreddits in the subreddits_map\n",
    "    idxs = subreddits_map.loc[group_subreddits].values\n",
    "\n",
    "    # create a sparse matrix with 1s in the indexes of the subreddits the author has posted in\n",
    "    v = sparse.dok_matrix((1, len(subreddits))) # dok = dictionary of keys; why not use dok_array?\n",
    "    for idx in idxs:\n",
    "        if not np.isnan(idx):  # is this really necessary?\n",
    "            v[0, idx] = 1\n",
    "    return v.tocsr()  # convert to compressed sparse row format\n",
    "\n",
    "extract_features(train_data[train_data.author=='RedThunder90'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bbff99c",
   "metadata": {
    "_uuid": "21a80468d90131f8021f446dcbcbc8848cdee0aa",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:16.380407Z",
     "iopub.status.busy": "2024-04-04T23:24:16.380011Z",
     "iopub.status.idle": "2024-04-04T23:24:28.167920Z",
     "shell.execute_reply": "2024-04-04T23:24:28.166659Z"
    },
    "papermill": {
     "duration": 11.799262,
     "end_time": "2024-04-04T23:24:28.170318",
     "exception": false,
     "start_time": "2024-04-04T23:24:16.371056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary mapping the author to the sparse matrix of subreddits they have\n",
    "# posted in\n",
    "\n",
    "features_dict: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "for author, group in train_data.groupby('author'):\n",
    "    features_dict[author] = extract_features(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63a4beb2",
   "metadata": {
    "_uuid": "d15816cd5bc076582b769255b697abd8e028cf43",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:28.188352Z",
     "iopub.status.busy": "2024-04-04T23:24:28.187218Z",
     "iopub.status.idle": "2024-04-04T23:24:28.259625Z",
     "shell.execute_reply": "2024-04-04T23:24:28.258463Z"
    },
    "papermill": {
     "duration": 0.084701,
     "end_time": "2024-04-04T23:24:28.262913",
     "exception": false,
     "start_time": "2024-04-04T23:24:28.178212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 49152 stored elements and shape (5000, 3468)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a sparse matrix with the labelled authors as rows and the subreddits they\n",
    "# have posted in as columns\n",
    "\n",
    "X = sparse.vstack([features_dict[author] for author in target.author])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb00e1fe",
   "metadata": {
    "_uuid": "dc9a85e3dcfab4f35601517fd7076d7f198fb686",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:28.281611Z",
     "iopub.status.busy": "2024-04-04T23:24:28.281187Z",
     "iopub.status.idle": "2024-04-04T23:24:28.286474Z",
     "shell.execute_reply": "2024-04-04T23:24:28.285379Z"
    },
    "papermill": {
     "duration": 0.017871,
     "end_time": "2024-04-04T23:24:28.288608",
     "exception": false,
     "start_time": "2024-04-04T23:24:28.270737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = target.gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6198ab93",
   "metadata": {
    "_uuid": "066e0e0632075a067ff46ce7eb8895c6f1a1caa9",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:28.309787Z",
     "iopub.status.busy": "2024-04-04T23:24:28.308568Z",
     "iopub.status.idle": "2024-04-04T23:24:28.347765Z",
     "shell.execute_reply": "2024-04-04T23:24:28.345974Z"
    },
    "papermill": {
     "duration": 0.053364,
     "end_time": "2024-04-04T23:24:28.350645",
     "exception": false,
     "start_time": "2024-04-04T23:24:28.297281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I still prefer to buy foods either grown locally or where animals are treated better, but this definitely has me looking at organic food differently.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_text(group: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Concatenates all the posts of an author into a single string.\n",
    "    \"\"\"\n",
    "    group_text = group['body'].astype(str).values\n",
    "    return \" \".join(group_text)\n",
    "\n",
    "extract_text(train_data[train_data.author == \"RedThunder90\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "092fd2d6",
   "metadata": {
    "_uuid": "96f1df44460515daab04a0c8a6a47ca5ba7eb171",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:28.367918Z",
     "iopub.status.busy": "2024-04-04T23:24:28.367522Z",
     "iopub.status.idle": "2024-04-04T23:24:29.214226Z",
     "shell.execute_reply": "2024-04-04T23:24:29.212992Z"
    },
    "papermill": {
     "duration": 0.858311,
     "end_time": "2024-04-04T23:24:29.216787",
     "exception": false,
     "start_time": "2024-04-04T23:24:28.358476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary mapping the author to the text of all their posts\n",
    "\n",
    "text_dict: dict[str, str] = {}\n",
    "\n",
    "for author, group in train_data.groupby('author'):\n",
    "    text_dict[author] = extract_text(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfa98389",
   "metadata": {
    "_uuid": "f9b126773b52e11764ca4dd1ecd23eb3999c8d8e",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:29.234561Z",
     "iopub.status.busy": "2024-04-04T23:24:29.233535Z",
     "iopub.status.idle": "2024-04-04T23:24:29.243020Z",
     "shell.execute_reply": "2024-04-04T23:24:29.241879Z"
    },
    "papermill": {
     "duration": 0.021071,
     "end_time": "2024-04-04T23:24:29.245662",
     "exception": false,
     "start_time": "2024-04-04T23:24:29.224591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I still prefer to buy foods either grown locally or where animals are treated better, but this definitely has me looking at organic food differently.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a list with the labelled authors as indexes and the text of all their posts\n",
    "# in the respective position\n",
    "\n",
    "author_text = [text_dict[author] for author in target.author]\n",
    "author_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f5300",
   "metadata": {},
   "source": [
    "At this point I have two data structures:\n",
    "- `X`: a sparse matrix N_authors x N_subreddits linking all the authors with the subreddits they have posted in\n",
    "- `author_text`: a list of length N_authors containing in position i all the text posted by author i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b918984e",
   "metadata": {
    "_uuid": "3068ae67a9ac5c4d74a69343fee81ba1ebaf6ee5",
    "papermill": {
     "duration": 0.007533,
     "end_time": "2024-04-04T23:24:29.261210",
     "exception": false,
     "start_time": "2024-04-04T23:24:29.253677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32de6296",
   "metadata": {
    "_uuid": "1bf7ebc57de0675737809d580ab996b8e34ac78d",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:29.280199Z",
     "iopub.status.busy": "2024-04-04T23:24:29.279551Z",
     "iopub.status.idle": "2024-04-04T23:24:29.285485Z",
     "shell.execute_reply": "2024-04-04T23:24:29.284535Z"
    },
    "papermill": {
     "duration": 0.019168,
     "end_time": "2024-04-04T23:24:29.288944",
     "exception": false,
     "start_time": "2024-04-04T23:24:29.269776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "class Model():\n",
    "    def predict_proba(self, X):\n",
    "        return np.zeros((X.shape[0], 2))\n",
    "    \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428d462",
   "metadata": {
    "_uuid": "50350b2033979099ec9e5dadd72a05f0b47f2744",
    "papermill": {
     "duration": 0.007821,
     "end_time": "2024-04-04T23:24:29.304878",
     "exception": false,
     "start_time": "2024-04-04T23:24:29.297057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b529a82",
   "metadata": {
    "_uuid": "39592879b9f88a56c88ea0f759bdc4f77b4133e3",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:29.323448Z",
     "iopub.status.busy": "2024-04-04T23:24:29.322780Z",
     "iopub.status.idle": "2024-04-04T23:24:35.868401Z",
     "shell.execute_reply": "2024-04-04T23:24:35.867104Z"
    },
    "papermill": {
     "duration": 6.558235,
     "end_time": "2024-04-04T23:24:35.871163",
     "exception": false,
     "start_time": "2024-04-04T23:24:29.312928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(f\"{data_dir}/test_data.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edbe1c37",
   "metadata": {
    "_uuid": "b8e6223088aedf8f4b827b6f7d555d2c22ced142",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:24:35.889240Z",
     "iopub.status.busy": "2024-04-04T23:24:35.888849Z",
     "iopub.status.idle": "2024-04-04T23:25:15.112963Z",
     "shell.execute_reply": "2024-04-04T23:25:15.111783Z"
    },
    "papermill": {
     "duration": 39.236409,
     "end_time": "2024-04-04T23:25:15.115564",
     "exception": false,
     "start_time": "2024-04-04T23:24:35.879155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_dict: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "for author, group in test_data.groupby('author'):\n",
    "    features_dict[author] = extract_features(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94752400",
   "metadata": {
    "_uuid": "74839ff4a639f7e3aac6596e1864332f5ac24d88",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:25:15.134108Z",
     "iopub.status.busy": "2024-04-04T23:25:15.133745Z",
     "iopub.status.idle": "2024-04-04T23:25:15.439424Z",
     "shell.execute_reply": "2024-04-04T23:25:15.438325Z"
    },
    "papermill": {
     "duration": 0.318213,
     "end_time": "2024-04-04T23:25:15.442025",
     "exception": false,
     "start_time": "2024-04-04T23:25:15.123812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15000x3468 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 144898 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = sparse.vstack([features_dict[author] for author in test_data.author.unique()])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b21293e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T23:25:15.461003Z",
     "iopub.status.busy": "2024-04-04T23:25:15.460640Z",
     "iopub.status.idle": "2024-04-04T23:25:18.346920Z",
     "shell.execute_reply": "2024-04-04T23:25:18.345525Z"
    },
    "papermill": {
     "duration": 2.899383,
     "end_time": "2024-04-04T23:25:18.349929",
     "exception": false,
     "start_time": "2024-04-04T23:25:15.450546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_dict = {}\n",
    "\n",
    "for author, group in test_data.groupby('author'):\n",
    "    text_dict[author] = extract_text(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45164ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T23:25:18.367590Z",
     "iopub.status.busy": "2024-04-04T23:25:18.367202Z",
     "iopub.status.idle": "2024-04-04T23:25:18.490889Z",
     "shell.execute_reply": "2024-04-04T23:25:18.489675Z"
    },
    "papermill": {
     "duration": 0.13556,
     "end_time": "2024-04-04T23:25:18.493561",
     "exception": false,
     "start_time": "2024-04-04T23:25:18.358001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "author_text_test = [text_dict[author] for author in test_data.author.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd6786dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T23:25:18.511298Z",
     "iopub.status.busy": "2024-04-04T23:25:18.510940Z",
     "iopub.status.idle": "2024-04-04T23:25:18.517467Z",
     "shell.execute_reply": "2024-04-04T23:25:18.516243Z"
    },
    "papermill": {
     "duration": 0.018216,
     "end_time": "2024-04-04T23:25:18.519925",
     "exception": false,
     "start_time": "2024-04-04T23:25:18.501709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I hadn't ever heard of them before joining this subreddit. They're not really a big thing in the US,\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_text_test[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d115688",
   "metadata": {
    "_uuid": "ce88990de3a60deedba91ce9f0d69211a09222e5",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:25:18.538243Z",
     "iopub.status.busy": "2024-04-04T23:25:18.537897Z",
     "iopub.status.idle": "2024-04-04T23:25:18.542741Z",
     "shell.execute_reply": "2024-04-04T23:25:18.541500Z"
    },
    "papermill": {
     "duration": 0.017291,
     "end_time": "2024-04-04T23:25:18.545232",
     "exception": false,
     "start_time": "2024-04-04T23:25:18.527941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d006443",
   "metadata": {
    "_uuid": "3d54c4654aae233bb9aac99a03fb5cd9dfee5915",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:25:18.563216Z",
     "iopub.status.busy": "2024-04-04T23:25:18.562854Z",
     "iopub.status.idle": "2024-04-04T23:25:18.673877Z",
     "shell.execute_reply": "2024-04-04T23:25:18.672584Z"
    },
    "papermill": {
     "duration": 0.12314,
     "end_time": "2024-04-04T23:25:18.676387",
     "exception": false,
     "start_time": "2024-04-04T23:25:18.553247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ejchristian86</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>savoytruffle</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hentercenter</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rick-o-suave</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author  gender\n",
       "0  ejchristian86     0.0\n",
       "1      ZenDragon     0.0\n",
       "2   savoytruffle     0.0\n",
       "3   hentercenter     0.0\n",
       "4   rick-o-suave     0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution = pd.DataFrame({\"author\": test_data.author.unique(), \"gender\": y_pred})\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3d6cf33",
   "metadata": {
    "_uuid": "a87ec4dad5a88d40a5562e983fd813cb956eb171",
    "execution": {
     "iopub.execute_input": "2024-04-04T23:25:18.695047Z",
     "iopub.status.busy": "2024-04-04T23:25:18.694679Z",
     "iopub.status.idle": "2024-04-04T23:25:18.722073Z",
     "shell.execute_reply": "2024-04-04T23:25:18.720977Z"
    },
    "papermill": {
     "duration": 0.039967,
     "end_time": "2024-04-04T23:25:18.724820",
     "exception": false,
     "start_time": "2024-04-04T23:25:18.684853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "solution.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49082564",
   "metadata": {
    "_uuid": "b1068a5b6920198541f469dc5b26e95b99d07252",
    "papermill": {
     "duration": 0.00864,
     "end_time": "2024-04-04T23:25:18.741796",
     "exception": false,
     "start_time": "2024-04-04T23:25:18.733156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now go to [Kaggle](https://www.kaggle.com/competitions/datamining2024/overview), click \"Submit Prediction\" and upload the file \"submission.csv\" to see the test score."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8145351,
     "sourceId": 74667,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "reddit_data_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 69.766181,
   "end_time": "2024-04-04T23:25:19.474364",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-04T23:24:09.708183",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
